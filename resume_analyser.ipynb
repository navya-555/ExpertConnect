{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DA\\SIH_24\\ExpertConnect\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GOOGLE_API\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DA\\SIH_24\\ExpertConnect\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume_with_gemini(resume_text,model):\n",
    "    prompt = f\"\"\"\n",
    "    You are analyzing a candidate's resume. Identify the key skills and domains based on their resume. Do not include any other information. Also make sure you only highlight prominent skills.\n",
    "\n",
    "    Output only the keywords for:\n",
    "    Skills: (e.g., Object Detection, OpenCV, Python)\n",
    "    Domains: (e.g., Computer Vision, Machine Learning)\n",
    "\n",
    "    You are supposed to follow these instructions while giving the output strictly.\n",
    "    1. Don't write anything else apart from skills and domain.\n",
    "    2. Use only ',' for separating two skills or domains.\n",
    "    3. Strictly follow the output format of the sample output.\n",
    "\n",
    "    Sample output:\n",
    "    Object Detection, OpenCV, Python\n",
    "    Computer Vision, Machine Learning\n",
    "    \"\"\"\n",
    "    \n",
    "    response = model.generate_content([prompt, resume_text])\n",
    "    output = response.text.strip().split('\\n')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navya-Sufyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, C, R, Git, GitHub, PyCharm, NumPy, Pandas, Power BI, Scikit-learn, YOLO, CNN, GPT, Gemini, Gemma, LLAMA3',\n",
       " 'Machine Learning, Deep Learning, Data Analysis, Generative AI']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"candidate/Sufyan_Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "result = analyze_resume_with_gemini(resume_text,gemini_model)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, C, R, Git, GitHub, PyCharm, NumPy, Pandas, Power BI, Scikit-learn, YOLO, CNN, GPT, Gemini, Gemma, LLAMA3',\n",
       " 'Machine Learning, Deep Learning, Computer Vision, Generative AI']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"Resume_Navya.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "result1 = analyze_resume_with_gemini(resume_text,gemini_model)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skills\n",
    "emb = emb_model.encode([result[0],\n",
    "                      result[0]])\n",
    "#cosine_similarity([emb[0]], [emb[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8515991]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#domain\n",
    "emb = emb_model.encode([result[1],\n",
    "                      result1[1]])\n",
    "cosine_similarity([emb[0]], [emb[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sambit-Snigdha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, C++, C, Scikit-learn, Keras, JupyterNotebooks, Git, Github, Huggingface, CNN, YOLO, GAN, Transformer, EfficientNet, DenseNet, Gemini, Gemma, StableDiffusion, Llama3, Pandas, NumPy, Matplotlib, Plotly, Flask, OpenCV, DeepSort, LightGBM, XgBoost, YOLOv8',\n",
       " 'Machine Learning, Deep Learning, Computer Vision, Generative AI, Data Analysis']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"Sambit Mallick Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "result = analyze_resume_with_gemini(resume_text,gemini_model)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, C++, C, Git, Github, PyCharm, Scikit-learn, YOLO, CNN, DenseNet, GAN, GPT, Gemini, Gemma, LLAMA3',\n",
       " 'Machine Learning, Deep Learning, Computer Vision, Generative AI, Quantum Machine Learning']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"resume_snigdha_paul.pdf-1.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "result1 = analyze_resume_with_gemini(resume_text,gemini_model)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88260144]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skills\n",
    "emb = emb_model.encode([result[0],\n",
    "                      result1[0]])\n",
    "cosine_similarity([emb[0]], [emb[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81917477]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#domain\n",
    "emb = emb_model.encode([result[1],\n",
    "                      result1[1]])\n",
    "cosine_similarity([emb[0]], [emb[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ayush-Sufyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, NumPy, Pandas, Matplotlib, Scikit-Learn, OpenCV, Dlib, pyAudioAnalysis, HTML, CSS, JavaScript, PHP, R',\n",
       " 'Machine Learning, Computer Vision, Data Science, Web Development, Data Analytics']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"Ayush_resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "result = analyze_resume_with_gemini(resume_text,gemini_model)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, C, R, Git, GitHub, PyCharm, NumPy, Pandas, Power BI, Scikit-learn, YOLO, CNN, GPT, Gemini, Gemma, LLAMA3',\n",
       " 'Machine Learning, Deep Learning, Data Analysis, Generative AI']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"Sufyan_Resume.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "result1 = analyze_resume_with_gemini(resume_text,gemini_model)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73804843]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skills\n",
    "emb = emb_model.encode([result[0],\n",
    "                      result1[0]])\n",
    "cosine_similarity([emb[0]], [emb[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6133897]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#domain\n",
    "emb = emb_model.encode([result[1],\n",
    "                      result1[1]])\n",
    "cosine_similarity([emb[0]], [emb[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_similarity(pdf1,pdf2,extracting_model,embedding_model):\n",
    "    resume1_text=extract_text_from_pdf(pdf1)\n",
    "    resume2_text=extract_text_from_pdf(pdf2)\n",
    "\n",
    "    resume1_details=analyze_resume_with_gemini(resume1_text,extracting_model)\n",
    "    resume2_details=analyze_resume_with_gemini(resume2_text,extracting_model)\n",
    "\n",
    "    skill_emb = embedding_model.encode([resume1_details[0], resume2_details[0]])\n",
    "    domain_emb = embedding_model.encode([resume1_details[1], resume2_details[1]])\n",
    "\n",
    "    skill_similarity = cosine_similarity([skill_emb[0]], [skill_emb[1]])\n",
    "    domain_similarity = cosine_similarity([domain_emb[0]], [domain_emb[1]])\n",
    "\n",
    "    similarity = (0.4 * skill_similarity) + (0.6 * domain_similarity)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9499607]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_similarity('Resume_Navya.pdf', 'Sufyan_Resume.pdf', gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8757193]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_similarity('Sambit Mallick Resume.pdf', 'resume_snigdha_paul.pdf-1.pdf', gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8812917]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_similarity('Sambit Mallick Resume.pdf', 'Sufyan_Resume.pdf', gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84288]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_similarity('Resume_Navya.pdf', 'resume_snigdha_paul.pdf-1.pdf', gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87421536]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_similarity('Resume_Navya.pdf', 'resume_snigdha_paul.pdf-1.pdf', gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47892556]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_similarity('resume_snigdha_paul.pdf-1.pdf', 'Pratik_resume_v2.pdf', gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engr (1).pdf\n",
      "engr (2).pdf\n",
      "engr (3).pdf\n",
      "engr (4).pdf\n",
      "HR (1).pdf\n",
      "HR (2).pdf\n",
      "HR (3).pdf\n",
      "Profile (1).pdf\n",
      "sales (1).pdf\n",
      "sales (2).pdf\n",
      "sales (3).pdf\n"
     ]
    }
   ],
   "source": [
    "def files(db):\n",
    "    for filename in os.listdir(db):\n",
    "        print(filename)\n",
    "\n",
    "files('experts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expertmatch(db,cand,extracting_model,embedding_model):\n",
    "    lst=[]\n",
    "    max=0\n",
    "    for filename in os.listdir(db):\n",
    "        f = os.path.join(db, filename)\n",
    "        text1=extract_text_from_pdf(f)\n",
    "        analysis1=analyze_resume_with_gemini(text1,extracting_model)\n",
    "        for cand_file in os.listdir(cand):\n",
    "            c = os.path.join(cand, cand_file)\n",
    "            text2=extract_text_from_pdf(c)\n",
    "            analysis2=analyze_resume_with_gemini(text2,extracting_model)\n",
    "            skill_emb = embedding_model.encode([analysis1[0], analysis2[0]])\n",
    "            domain_emb = embedding_model.encode([analysis1[1], analysis2[1]])\n",
    "            skill_similarity = cosine_similarity([skill_emb[0]], [skill_emb[1]])\n",
    "            domain_similarity = cosine_similarity([domain_emb[0]], [domain_emb[1]])\n",
    "            similarity = (0.4 * skill_similarity) + (0.6 * domain_similarity)\n",
    "            lst.append(similarity)\n",
    "            if max<similarity:\n",
    "                max=similarity\n",
    "                file=filename\n",
    "    return max,file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.77082264]], dtype=float32), 'Akash Kundu.pdf')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expertmatch('experts','candidate',gemini_model, emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_domain_from_job_des(text,model=gemini_model):\n",
    "    prompt = f\"\"\"\n",
    "    You are analyzing a job. Identify the key skills and domains based on the description. Do not include any other information. Also make sure you only highlight prominent skills.\n",
    "\n",
    "    Output only the keywords for:\n",
    "    Skills: (e.g., Object Detection, OpenCV, Python)\n",
    "    Domains: (e.g., Computer Vision, Machine Learning)\n",
    "\n",
    "    You are supposed to follow these instructions while giving the output strictly.\n",
    "    1. Don't write anything else apart from skills and domain.\n",
    "    2. Use only ',' for separating two skills or domains.\n",
    "    3. Strictly follow the output format of the sample output.\n",
    "\n",
    "    Sample output:\n",
    "    Object Detection, OpenCV, Python\n",
    "    Computer Vision, Machine Learning\n",
    "    \"\"\"\n",
    "    \n",
    "    response = model.generate_content([prompt, text])\n",
    "    output = response.text.strip().split('\\n')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python, SQL, Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch, Git, AWS, Azure, GCP',\n",
       " 'Machine Learning, Data Science, Data Engineering, Cloud Computing']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"Data_Scientist_Job_Description.pdf\"\n",
    "jd_text = extract_text_from_pdf(pdf_path)\n",
    "result = analyze_resume_with_gemini(jd_text,gemini_model)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
